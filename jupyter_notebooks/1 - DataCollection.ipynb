{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0aStgWSO0E0E"
      },
      "source": [
        "# **Data Collection Notebook**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1eLEkw5O0ECa"
      },
      "source": [
        "## Objectives\n",
        "\n",
        "* Fetch data from Kaggle and save as raw data\n",
        "* Inspect the data for missing values and data types and save it to outputs/datasets/collection\n",
        "\n",
        "## Inputs\n",
        "\n",
        "* Kaggle JSON file - the authentication token.\n",
        "* Kaggle dataset URL - [Predicting Hospital Readmissions](https://www.kaggle.com/datasets/dubradave/hospital-readmissions)\n",
        "\n",
        "## Outputs\n",
        "\n",
        "* outputs/datasets/collection/HospitalReadmissions.csv\n",
        "\n",
        "## Additional Comments\n",
        "\n",
        "* No additional comments  \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9uWZXH9LwoQg"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cqP-UeN-z3i2"
      },
      "source": [
        "# Change working directory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aOGIGS-uz3i2"
      },
      "source": [
        "We need to change the working directory from its current folder to its parent folder\n",
        "* We access the current directory with os.getcwd()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wZfF_j-Bz3i4",
        "outputId": "66943449-1436-4c3d-85c7-b85f9f78349b"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "current_dir = os.getcwd()\n",
        "current_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9MWW8E7lz3i7"
      },
      "source": [
        "We want to make the parent of the current directory the new current directory\n",
        "* os.path.dirname() gets the parent directory\n",
        "* os.chir() defines the new current directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TwHsQRWjz3i9",
        "outputId": "86849db3-cd2f-4cc5-ebb8-2d0caafa1a2c"
      },
      "outputs": [],
      "source": [
        "os.chdir(os.path.dirname(current_dir))\n",
        "print(\"You set a new current directory\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M_xPk_Ijz3i-"
      },
      "source": [
        "Confirm the new current directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vz3S-_kjz3jA",
        "outputId": "00b79ae4-75d0-4a96-d193-ac9ef9847ea2"
      },
      "outputs": [],
      "source": [
        "current_dir = os.getcwd()\n",
        "current_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Import Dataset from Kaggle"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "First, install kaggle to access the kaggle API and import the raw data set.\n",
        "\n",
        "A valid account must be registered with Kaggle to obtain an API key (as a JSON-file)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "! pip install kaggle==1.5.12"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Make the kaggle authentication token available for the session."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ['KAGGLE_CONFIG_DIR'] = os.getcwd()\n",
        "! chmod 600 kaggle.json"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Define the kaggle dataset and the destination folder and then download it. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "KaggleDatasetPath = \"dubradave/hospital-readmissions\"\n",
        "DestinationFolder = \"inputs/datasets/raw\"\n",
        "! kaggle datasets download -d {KaggleDatasetPath} -p {DestinationFolder}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Unzip the downloaded file, delete the zip file and delete the kaggle.json file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import zipfile\n",
        "\n",
        "# Unzip all .zip files in the destination folder\n",
        "for file_name in os.listdir(DestinationFolder):\n",
        "    if file_name.endswith('.zip'):\n",
        "        file_path = os.path.join(DestinationFolder, file_name)\n",
        "        with zipfile.ZipFile(file_path, 'r') as zip_ref:\n",
        "            zip_ref.extractall(DestinationFolder)\n",
        "        os.remove(file_path)  # Remove the zip file after extraction\n",
        "\n",
        "# Remove the kaggle.json file if it exists\n",
        "kaggle_json_path = 'kaggle.json'\n",
        "\n",
        "if os.path.exists(kaggle_json_path):\n",
        "    os.remove(kaggle_json_path)\n",
        "\n",
        "print(\"Files unzipped, zip files and kaggle.json removed.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZY3l0-AxO93d"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uFQo3ycuO-v6"
      },
      "source": [
        "# Load and Inspect the Kaggle Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Using the pandas library, the dataset can be loaded as a dataframe and the data inspected."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(f\"inputs/datasets/raw/hospital_readmissions.csv\")\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "By running the command below we will be able to see the data type and size of the dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Then we check for missing values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df.isnull().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "From the above output we can see that there aren't any missing values, however from the Dataframe above we can see in the 'medical_specialty' a value of 'Missing'. \n",
        "\n",
        "* To further investigate this variable we run the cell bellow and we see that actually almost half of the rows are labelled 'Missing'. So, those were actual missing values, which were labelled 'Missing'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df['medical_specialty'].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Also, we can see that half of the columns are object. What we would like is to convert, already, those variables with a 'yes' and 'no' values and map them with 0 to 'no' and 1 to 'yes', and make them numeric.\n",
        "\n",
        "* Below, we first check to see which variables are categorical and which boolean and then we convert the boolean."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# loops through all columns in the dataframe and \n",
        "# prints the value counts for each column that is of type 'object'\n",
        "\n",
        "for col in df.columns:\n",
        "    if df[col].dtype == 'object':\n",
        "        print(f\"**{col}**:\\n {df[col].value_counts()}\\n\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# maps the boolean values to the corresponding numerical values\n",
        "\n",
        "boolean_vars = ['change', 'diabetes_med', 'readmitted']\n",
        "\n",
        "for var in boolean_vars:\n",
        "    df[var] = df[var].map({'no': 0, 'yes': 1})\n",
        "    print(f\"**{var}**:\\n {df[var].value_counts()}\\n\\n\")\n",
        "\n",
        "df.head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ltNetd085qHf"
      },
      "source": [
        "# Save the Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "  The modified dataset is saved to the outputs directory."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aKlnIozA4eQO",
        "outputId": "fd09bc1f-adb1-4511-f6ce-492a6af570c0"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "try:\n",
        "  os.makedirs(name=\"outputs/datasets/collection\")\n",
        "except Exception as e:\n",
        "  print(e)\n",
        "\n",
        "df.to_csv(\"outputs/datasets/collection/HospitalReadmissions.csv\", index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Coclusions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In this notebook we have achieve the following:\n",
        "\n",
        "* Successfully download, unzip and save the dataset using the Gaggle API\n",
        "* Inspected the dataset for missing values and identified no actual missing values, except in the \"medical_specialty\" variable were almost half of the rows were already labelled \"Missing\". \n",
        "* Inspected the data type of the \"change\", \"diabetes_med\" and \"readmitted\" variables were mapped to numerical values \n",
        "* The dataset was saved in the outputs directory."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Next steps"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In the next Notebook we will begin an EDA using Pandas profiling and correlation studies and start addressing the business requirement 1.\n",
        "\n",
        "This will take us to the 'Data Understanding' of the CRISP-DM workflow."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Data Practitioner Jupyter Notebook.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "interpreter": {
      "hash": "8b8334dab9339717f727a1deaf837b322d7a41c20d15cc86be99a8e69ceec8ce"
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    },
    "orig_nbformat": 2
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
